{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2002__NBA_Game_Outcome_Predictions.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3k1nVJK6A4O"
      },
      "source": [
        "## Import Dependencies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8BOl5-P6vdv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import lxml.html as lh\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('display.max_columns', None)\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import neighbors\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from operator import itemgetter\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CyCbu_j8Ykn"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmfwIo7yI16j"
      },
      "source": [
        "List of NBA Teams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4NrZPwhDU42"
      },
      "source": [
        "TEAMS = ['ATL', 'BOS' ,'CHA' ,'CHI', 'CLE', 'DAL' ,'DEN' ,'DET' ,'GS', 'HOU' ,'IND', 'LAC',\n",
        " 'LAL', 'MEM', 'MIA', 'MIL' ,'MIN' ,'NJ', 'NY', 'ORL' ,'PHI' ,'PHX', 'POR', 'SAC',\n",
        " 'SA', 'SEA', 'TOR' ,'UTAH' ,'WSH']\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTB53vW-6-iT"
      },
      "source": [
        "##Team Season Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTavoRRM4c8H"
      },
      "source": [
        "d = os.path.join(\"/content/team_season.txt\")\n",
        "team_season = np.loadtxt(d, delimiter=',', dtype='str')\n",
        "# convert team_season into a csv file\n",
        "# get header\n",
        "header = team_season[0]\n",
        "# remove first row, header\n",
        "team_season = team_season[1:]\n",
        "# convert it to an CSV file\n",
        "pd.DataFrame(team_season).to_csv(\"team_stats.csv\", header = header,index=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "OTzi160_8j0t",
        "outputId": "76abb851-8ed1-4f1f-8e71-a527355c2882"
      },
      "source": [
        "col_list = [\"team\", \"year\",'o_ftm','o_reb' ,'o_asts' ,'o_pf' ,'o_stl' ,'o_to' ,'o_blk', 'o_3pm','o_pts',\n",
        " 'd_ftm' ,'d_reb', 'd_asts' ,'d_pf',\n",
        " 'd_stl', 'd_to', 'd_blk','d_3pm','d_pts','won','lost']\n",
        "\n",
        "team_stats = pd.read_csv(\"team_stats.csv\",usecols=col_list)\n",
        "\n",
        "#get team stats for 2001 \n",
        "stats_df = team_stats.loc[team_stats[\"year\"] == 2001]\n",
        "stats_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team</th>\n",
              "      <th>year</th>\n",
              "      <th>o_ftm</th>\n",
              "      <th>o_reb</th>\n",
              "      <th>o_asts</th>\n",
              "      <th>o_pf</th>\n",
              "      <th>o_stl</th>\n",
              "      <th>o_to</th>\n",
              "      <th>o_blk</th>\n",
              "      <th>o_3pm</th>\n",
              "      <th>o_pts</th>\n",
              "      <th>d_ftm</th>\n",
              "      <th>d_reb</th>\n",
              "      <th>d_asts</th>\n",
              "      <th>d_pf</th>\n",
              "      <th>d_stl</th>\n",
              "      <th>d_to</th>\n",
              "      <th>d_blk</th>\n",
              "      <th>d_3pm</th>\n",
              "      <th>d_pts</th>\n",
              "      <th>won</th>\n",
              "      <th>lost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1070</th>\n",
              "      <td>ATL</td>\n",
              "      <td>2001</td>\n",
              "      <td>1486</td>\n",
              "      <td>3400</td>\n",
              "      <td>1656</td>\n",
              "      <td>1702</td>\n",
              "      <td>667</td>\n",
              "      <td>1203</td>\n",
              "      <td>350</td>\n",
              "      <td>423</td>\n",
              "      <td>7711</td>\n",
              "      <td>1456</td>\n",
              "      <td>3525</td>\n",
              "      <td>1856</td>\n",
              "      <td>1647</td>\n",
              "      <td>703</td>\n",
              "      <td>1177</td>\n",
              "      <td>508</td>\n",
              "      <td>472</td>\n",
              "      <td>8058</td>\n",
              "      <td>33</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1071</th>\n",
              "      <td>BOS</td>\n",
              "      <td>2001</td>\n",
              "      <td>1498</td>\n",
              "      <td>3461</td>\n",
              "      <td>1722</td>\n",
              "      <td>1775</td>\n",
              "      <td>793</td>\n",
              "      <td>1082</td>\n",
              "      <td>293</td>\n",
              "      <td>699</td>\n",
              "      <td>7901</td>\n",
              "      <td>1612</td>\n",
              "      <td>3760</td>\n",
              "      <td>1802</td>\n",
              "      <td>1733</td>\n",
              "      <td>623</td>\n",
              "      <td>1284</td>\n",
              "      <td>474</td>\n",
              "      <td>514</td>\n",
              "      <td>7720</td>\n",
              "      <td>49</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1072</th>\n",
              "      <td>CHA</td>\n",
              "      <td>2001</td>\n",
              "      <td>1568</td>\n",
              "      <td>3564</td>\n",
              "      <td>1759</td>\n",
              "      <td>1747</td>\n",
              "      <td>653</td>\n",
              "      <td>1108</td>\n",
              "      <td>456</td>\n",
              "      <td>346</td>\n",
              "      <td>7700</td>\n",
              "      <td>1488</td>\n",
              "      <td>3362</td>\n",
              "      <td>1639</td>\n",
              "      <td>1702</td>\n",
              "      <td>625</td>\n",
              "      <td>1074</td>\n",
              "      <td>426</td>\n",
              "      <td>433</td>\n",
              "      <td>7621</td>\n",
              "      <td>44</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1073</th>\n",
              "      <td>CHI</td>\n",
              "      <td>2001</td>\n",
              "      <td>1413</td>\n",
              "      <td>3283</td>\n",
              "      <td>1817</td>\n",
              "      <td>1834</td>\n",
              "      <td>633</td>\n",
              "      <td>1169</td>\n",
              "      <td>361</td>\n",
              "      <td>300</td>\n",
              "      <td>7335</td>\n",
              "      <td>1560</td>\n",
              "      <td>3497</td>\n",
              "      <td>2066</td>\n",
              "      <td>1716</td>\n",
              "      <td>681</td>\n",
              "      <td>1122</td>\n",
              "      <td>399</td>\n",
              "      <td>421</td>\n",
              "      <td>8035</td>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>CLE</td>\n",
              "      <td>2001</td>\n",
              "      <td>1529</td>\n",
              "      <td>3451</td>\n",
              "      <td>1891</td>\n",
              "      <td>1752</td>\n",
              "      <td>572</td>\n",
              "      <td>1129</td>\n",
              "      <td>470</td>\n",
              "      <td>387</td>\n",
              "      <td>7812</td>\n",
              "      <td>1506</td>\n",
              "      <td>3310</td>\n",
              "      <td>1989</td>\n",
              "      <td>1638</td>\n",
              "      <td>602</td>\n",
              "      <td>1018</td>\n",
              "      <td>459</td>\n",
              "      <td>473</td>\n",
              "      <td>8085</td>\n",
              "      <td>29</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     team  year  o_ftm  o_reb  o_asts  o_pf  o_stl  o_to  o_blk  o_3pm  o_pts  \\\n",
              "1070  ATL  2001   1486   3400    1656  1702    667  1203    350    423   7711   \n",
              "1071  BOS  2001   1498   3461    1722  1775    793  1082    293    699   7901   \n",
              "1072  CHA  2001   1568   3564    1759  1747    653  1108    456    346   7700   \n",
              "1073  CHI  2001   1413   3283    1817  1834    633  1169    361    300   7335   \n",
              "1074  CLE  2001   1529   3451    1891  1752    572  1129    470    387   7812   \n",
              "\n",
              "      d_ftm  d_reb  d_asts  d_pf  d_stl  d_to  d_blk  d_3pm  d_pts  won  lost  \n",
              "1070   1456   3525    1856  1647    703  1177    508    472   8058   33    49  \n",
              "1071   1612   3760    1802  1733    623  1284    474    514   7720   49    33  \n",
              "1072   1488   3362    1639  1702    625  1074    426    433   7621   44    38  \n",
              "1073   1560   3497    2066  1716    681  1122    399    421   8035   21    61  \n",
              "1074   1506   3310    1989  1638    602  1018    459    473   8085   29    53  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHUqWcSx_Nml"
      },
      "source": [
        "TeamStats_2001 = np.array(stats_df)\n",
        "#skip first 2 columns (team name and year)\n",
        "team_stats = TeamStats_2001[:,2 :] "
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqJmY8_S_bxg"
      },
      "source": [
        "## Game Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "N2_NSnMaAG3t",
        "outputId": "244c3519-53f1-4cbb-d2b9-f36c43568293"
      },
      "source": [
        "col_list = ['home_team','home_points','away_team','away_points']\n",
        "\n",
        "games = pd.read_csv(\"nba_games_2002_2003.csv\",usecols=col_list)\n",
        "games = games.loc[games[\"home_team\"] != 'NO']\n",
        "games.head()\n",
        "games = games.loc[games[\"away_team\"] != 'NO']\n",
        "games.head()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>home_team</th>\n",
              "      <th>home_points</th>\n",
              "      <th>away_team</th>\n",
              "      <th>away_points</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LAL</td>\n",
              "      <td>81</td>\n",
              "      <td>SA</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ORL</td>\n",
              "      <td>95</td>\n",
              "      <td>PHI</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SAC</td>\n",
              "      <td>94</td>\n",
              "      <td>CLE</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BOS</td>\n",
              "      <td>96</td>\n",
              "      <td>CHI</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DET</td>\n",
              "      <td>86</td>\n",
              "      <td>NY</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  home_team  home_points away_team  away_points\n",
              "0       LAL           81        SA           87\n",
              "1       ORL           95       PHI           88\n",
              "2       SAC           94       CLE           67\n",
              "3       BOS           96       CHI           99\n",
              "5       DET           86        NY           77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiIYtQjkD76a"
      },
      "source": [
        "# get outcome results from the game data ie. 0 if away_points are higher than home_points and 1 if home_points are higher than away_points\n",
        "game_data =np.array(games)\n",
        "game = []\n",
        "for i in range(len(game_data)):\n",
        "  x = []\n",
        "  x.append(game_data[i][0])\n",
        "  x.append(game_data[i][2])\n",
        "  outcome = game_data[i][1]-game_data[i][3]\n",
        "  if outcome < 0:\n",
        "    x.append(0)\n",
        "  else:\n",
        "    x.append(1)\n",
        "  game.append(x)\n",
        "game_data = np.array(game)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThgXliu_-_lI"
      },
      "source": [
        "# Create the Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqurKFce0_Cy"
      },
      "source": [
        "def createDataSet(game_data,usePCA,isNormalized):\r\n",
        "  pca = PCA(n_components=18)\r\n",
        "  normalizer = preprocessing.MinMaxScaler()\r\n",
        "  data = []\r\n",
        "  for i in range(len(game_data)):\r\n",
        "\r\n",
        "    \r\n",
        "    # find location home_team stats\r\n",
        "    index = TEAMS.index(game_data[i][0])\r\n",
        "    # get home_team stats\r\n",
        "    home_side = team_stats[index]\r\n",
        " \r\n",
        "    # get away_team stats\r\n",
        "    index = TEAMS.index(game_data[i][1])\r\n",
        "    away_side =  team_stats[index]\r\n",
        "    \r\n",
        "  \r\n",
        "    # create feature vector concatenate home_team stats and away_team stats\r\n",
        "    feature_vector = np.concatenate((home_side, away_side), axis=None)\r\n",
        "\r\n",
        "    data.append(feature_vector)\r\n",
        "\r\n",
        "  #NORMALIZE\r\n",
        "  if (isNormalized):\r\n",
        "    data = normalizer.fit_transform(data)\r\n",
        "\r\n",
        "  #reduce feature vector with PCA\r\n",
        "  if (usePCA):\r\n",
        "    data = pca.fit_transform(data)\r\n",
        "\r\n",
        "  ndata = []\r\n",
        "\r\n",
        "  for z in range(len(game_data)):\r\n",
        "    result = []\r\n",
        "    result.append(game_data[z][2])\r\n",
        "\r\n",
        "    # create feature vector by appending the outcome labled result of the game  \r\n",
        "    feature_vector = np.concatenate((data[z],result), axis=None)\r\n",
        "    ndata.append(feature_vector)\r\n",
        "\r\n",
        "  data = np.array(ndata)\r\n",
        "  print(\"feature vector size\", data.shape[1])\r\n",
        "  \r\n",
        "  return data"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxR2f-BEBinK"
      },
      "source": [
        "# ML Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulYkSsQEBinK"
      },
      "source": [
        "Scoring matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXmmSGV-FUQE"
      },
      "source": [
        "def scores(model):\n",
        "    \n",
        "    model.fit(xtrain, ytrain)\n",
        "    y_pred = model.predict(xtest)\n",
        "    \n",
        "    print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_pred))\n",
        "    print(\"Recall: %.3f\" % metrics.recall_score(ytest, y_pred))\n",
        "    print(\"Precision: %.3f\" % metrics.precision_score(ytest, y_pred))\n",
        "    print(\"F1: %.3f\" % metrics.f1_score(ytest, y_pred))\n",
        "    \n",
        "    proba = model.predict_proba(xtest)\n",
        "    print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
        "\n",
        "    pos_prob = proba[:, 1]\n",
        "    print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, pos_prob))\n",
        "    \n",
        "    cv = cross_val_score(model, xtest, ytest, cv = 10, scoring = 'accuracy')\n",
        "    print(\"Accuracy (cross validation score): %0.3f (+/- %0.3f)\" % (cv.mean(), cv.std() * 2))\n",
        "\n",
        "    print(\"confusion matrix\")\n",
        "    print( metrics.confusion_matrix(ytest, y_pred) )\n",
        "    \n",
        "    return y_pred"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYw2DkTQBinL"
      },
      "source": [
        "## Training and Testing our Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmPmA8NgIGPn"
      },
      "source": [
        "Get the different Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qkc947tPc4H"
      },
      "source": [
        "#Original data\n",
        "dA = createDataSet(game_data,False,False)\n",
        "#PCA with Normalized Data\n",
        "dB = createDataSet(game_data,True,True)\n",
        "#PCA Data\n",
        "dC = createDataSet(game_data,True,False)\n",
        "#Normalized Data\n",
        "dD = createDataSet(game_data,False,True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TMlqIcvILrf"
      },
      "source": [
        "**Results using Original Data (NO PCA or Normalization)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMVcNEtmdibd",
        "outputId": "f7c1cc34-c084-42c0-8480-64cdc52b07d1"
      },
      "source": [
        "trainA, testA = train_test_split( dA, test_size = 0.25,random_state = 20)\n",
        "\n",
        "xtrain = trainA[:, :-1].astype(float)# for all but last column\n",
        "ytrain = trainA[:, -1].astype(int) # for last column (result label )\n",
        "\n",
        "xtest = testA[:, :-1].astype(float) \n",
        "ytest = testA[:, -1].astype(int) \n",
        "\n",
        "print(\"Training set size: %.0f\" % len(xtrain))\n",
        "print(\"Testing set size: %.0f\" % len(xtest))\n",
        "print()\n",
        "\n",
        "print(\"SVM STATS\")\n",
        "#svc = SVC(probability=True)\n",
        "svc = SVC(kernel='rbf',C=100,probability=True)\n",
        "y_svc = scores(svc)\n",
        "print()\n",
        "\n",
        "print(\"knn STATS\")\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors = 12, weights = 'uniform')\n",
        "y_knn = scores(knn)\n",
        "print()\n",
        "\n",
        "print(\"logreg STATS\")\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "y_log = scores(logreg)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: 830\n",
            "Testing set size: 277\n",
            "\n",
            "SVM STATS\n",
            "Accuracy score: 0.693\n",
            "Recall: 0.921\n",
            "Precision: 0.697\n",
            "F1: 0.793\n",
            "Log loss: 0.592\n",
            "Area under ROC curve: 0.714\n",
            "Accuracy (cross validation score): 0.650 (+/- 0.103)\n",
            "confusion matrix\n",
            "[[ 29  71]\n",
            " [ 14 163]]\n",
            "\n",
            "knn STATS\n",
            "Accuracy score: 0.708\n",
            "Recall: 0.814\n",
            "Precision: 0.750\n",
            "F1: 0.780\n",
            "Log loss: 0.808\n",
            "Area under ROC curve: 0.718\n",
            "Accuracy (cross validation score): 0.621 (+/- 0.154)\n",
            "confusion matrix\n",
            "[[ 52  48]\n",
            " [ 33 144]]\n",
            "\n",
            "logreg STATS\n",
            "Accuracy score: 0.668\n",
            "Recall: 0.785\n",
            "Precision: 0.720\n",
            "F1: 0.751\n",
            "Log loss: 0.602\n",
            "Area under ROC curve: 0.689\n",
            "Accuracy (cross validation score): 0.635 (+/- 0.177)\n",
            "confusion matrix\n",
            "[[ 46  54]\n",
            " [ 38 139]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7KgiTCNOrxV"
      },
      "source": [
        "**Results using PCA Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_E5BzpyBinO",
        "outputId": "de0300b6-496a-48c6-d0b4-4eec76ba1f01"
      },
      "source": [
        "trainA, testA = train_test_split( dC, test_size = 0.25,random_state = 20)\n",
        "\n",
        "xtrain = trainA[:, :-1].astype(float)# for all but last column\n",
        "ytrain = trainA[:, -1].astype(int) # for last column (result label )\n",
        "\n",
        "xtest = testA[:, :-1].astype(float) \n",
        "ytest = testA[:, -1].astype(int) \n",
        "\n",
        "\n",
        "\n",
        "print(\"SVM STATS\")\n",
        "#svc = SVC(probability=True)\n",
        "svc = SVC(kernel='rbf',probability=True)\n",
        "y_svc = scores(svc)\n",
        "print()\n",
        "\n",
        "print(\"knn STATS\")\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors = 18, weights = 'uniform')\n",
        "y_knn = scores(knn)\n",
        "print()\n",
        "\n",
        "print(\"logreg STATS\")\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "y_log = scores(logreg)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM STATS\n",
            "Accuracy score: 0.704\n",
            "Recall: 0.876\n",
            "Precision: 0.721\n",
            "F1: 0.791\n",
            "Log loss: 0.591\n",
            "Area under ROC curve: 0.711\n",
            "Accuracy (cross validation score): 0.660 (+/- 0.119)\n",
            "confusion matrix\n",
            "[[ 40  60]\n",
            " [ 22 155]]\n",
            "\n",
            "knn STATS\n",
            "Accuracy score: 0.690\n",
            "Recall: 0.831\n",
            "Precision: 0.724\n",
            "F1: 0.774\n",
            "Log loss: 0.809\n",
            "Area under ROC curve: 0.721\n",
            "Accuracy (cross validation score): 0.642 (+/- 0.161)\n",
            "confusion matrix\n",
            "[[ 44  56]\n",
            " [ 30 147]]\n",
            "\n",
            "logreg STATS\n",
            "Accuracy score: 0.715\n",
            "Recall: 0.898\n",
            "Precision: 0.723\n",
            "F1: 0.801\n",
            "Log loss: 0.589\n",
            "Area under ROC curve: 0.707\n",
            "Accuracy (cross validation score): 0.690 (+/- 0.126)\n",
            "confusion matrix\n",
            "[[ 39  61]\n",
            " [ 18 159]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3__VzRmO3or"
      },
      "source": [
        "**Results using Normalized Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYaqQgvlBinO",
        "outputId": "ea5050d9-ffd4-4ace-c2b6-5964544a371c"
      },
      "source": [
        "trainA, testA = train_test_split( dD, test_size = 0.25,random_state = 20)\n",
        "\n",
        "xtrain = trainA[:, :-1].astype(float)# for all but last column\n",
        "ytrain = trainA[:, -1].astype(int) # for last column (result label )\n",
        "\n",
        "xtest = testA[:, :-1].astype(float) \n",
        "ytest = testA[:, -1].astype(int) \n",
        "\n",
        "\n",
        "print(\"SVM STATS\")\n",
        "#svc = SVC(probability=True)\n",
        "svc = SVC(kernel='rbf',C=100,probability=True)\n",
        "y_svc = scores(svc)\n",
        "print()\n",
        "\n",
        "print(\"knn STATS\")\n",
        "knn = neighbors.KNeighborsClassifier()\n",
        "y_knn = scores(knn)\n",
        "print()\n",
        "\n",
        "print(\"logreg STATS\")\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "y_log = scores(logreg)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM STATS\n",
            "Accuracy score: 0.599\n",
            "Recall: 0.695\n",
            "Precision: 0.683\n",
            "F1: 0.689\n",
            "Log loss: 0.633\n",
            "Area under ROC curve: 0.633\n",
            "Accuracy (cross validation score): 0.563 (+/- 0.186)\n",
            "confusion matrix\n",
            "[[ 43  57]\n",
            " [ 54 123]]\n",
            "\n",
            "knn STATS\n",
            "Accuracy score: 0.679\n",
            "Recall: 0.825\n",
            "Precision: 0.716\n",
            "F1: 0.766\n",
            "Log loss: 1.893\n",
            "Area under ROC curve: 0.670\n",
            "Accuracy (cross validation score): 0.624 (+/- 0.152)\n",
            "confusion matrix\n",
            "[[ 42  58]\n",
            " [ 31 146]]\n",
            "\n",
            "logreg STATS\n",
            "Accuracy score: 0.704\n",
            "Recall: 0.870\n",
            "Precision: 0.723\n",
            "F1: 0.790\n",
            "Log loss: 0.592\n",
            "Area under ROC curve: 0.702\n",
            "Accuracy (cross validation score): 0.690 (+/- 0.140)\n",
            "confusion matrix\n",
            "[[ 41  59]\n",
            " [ 23 154]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ86NDlGPBNy"
      },
      "source": [
        "**Results using PCA with Normalized Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhsa-BB7BinN",
        "outputId": "50c7b408-9085-406d-fae0-3da52302efb8"
      },
      "source": [
        "trainA, testA = train_test_split( dB, test_size = 0.25,random_state = 20)\n",
        "\n",
        "xtrain = trainA[:, :-1].astype(float)# for all but last column\n",
        "ytrain = trainA[:, -1].astype(int) # for last column (result label )\n",
        "\n",
        "xtest = testA[:, :-1].astype(float) \n",
        "ytest = testA[:, -1].astype(int) \n",
        "\n",
        "\n",
        "\n",
        "print(\"SVM STATS\")\n",
        "#svc = SVC(probability=True)\n",
        "svc = SVC(kernel='rbf',probability=True)\n",
        "y_svc = scores(svc)\n",
        "print()\n",
        "\n",
        "print(\"knn STATS\")\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors = 12, weights = 'uniform')\n",
        "y_knn = scores(knn)\n",
        "print()\n",
        "\n",
        "print(\"logreg STATS\")\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "y_log = scores(logreg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM STATS\n",
            "Accuracy score: 0.697\n",
            "Recall: 0.864\n",
            "Precision: 0.718\n",
            "F1: 0.785\n",
            "Log loss: 0.597\n",
            "Area under ROC curve: 0.697\n",
            "Accuracy (cross validation score): 0.621 (+/- 0.114)\n",
            "confusion matrix\n",
            "[[ 40  60]\n",
            " [ 24 153]]\n",
            "\n",
            "knn STATS\n",
            "Accuracy score: 0.661\n",
            "Recall: 0.768\n",
            "Precision: 0.720\n",
            "F1: 0.743\n",
            "Log loss: 0.943\n",
            "Area under ROC curve: 0.698\n",
            "Accuracy (cross validation score): 0.606 (+/- 0.145)\n",
            "confusion matrix\n",
            "[[ 47  53]\n",
            " [ 41 136]]\n",
            "\n",
            "logreg STATS\n",
            "Accuracy score: 0.675\n",
            "Recall: 0.859\n",
            "Precision: 0.700\n",
            "F1: 0.772\n",
            "Log loss: 0.596\n",
            "Area under ROC curve: 0.698\n",
            "Accuracy (cross validation score): 0.668 (+/- 0.126)\n",
            "confusion matrix\n",
            "[[ 35  65]\n",
            " [ 25 152]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}